<!--

 * @Author: poowicat
 * @Date: 2022-03-11 15:05:56
 * @LastEditTime: 2022-05-25 11:18:49
 * @LastEditors: huangziyi
 * @Description: 《深入浅出机器学习第七章 学习笔记》
 * @FilePath: \深入浅出机器学习\07.支持向量机SVM——专治线性不可分.md
-->
![svm](https://pic2.zhimg.com/v2-e833772fe2044ad9c353fb0173bd0b79_1440w.jpg?source=172ae18b)

### 支持向量

#### 线性可分

- 在二维平面上两点被一条直线完全分开叫作线性可分；

  

#### 最大间隔超平面

- 为了使这个二维超平面具有**鲁棒性**
- 我们回去找**最佳**超平面
- 以**最大间隔**把两类样本分开的超平面，也称之为最大间隔超平面
- **两类样本**分别分割在该超平面的**两侧**
- 两侧距离超平面最近的样本点到超平面的**距离被最大化**

#### 支持向量

- 样本距离超平面最近的一些点，这些点叫作支持向量；
- ![image](https://cdn.jsdelivr.net/gh/poowicat/pic_store@main/blog/image.44bwzc6t2s80.webp)

#### 最优化问题

- svm想要找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面

- 任意超平面可以用下面的线性方程来描述：

- $$
  \omega ^{T}\chi + b= 0
  $$

- 二维空间点（x, y) 到直线Ax + By + C = 0 的距离公式是：

- $$
  \frac{|A\chi + By + C|}{\sqrt{A^{2} + B^{2}}}
  $$

- 扩展到N维空间后，点x = （x1， x2， ... xn) 到直线
  $$
  \omega ^{T}\chi + b= 0
  $$
  的距离为：
  $$
  \frac{|\omega ^{T}\chi + b|}{||\omega ||}
  $$
  其中
  $$
  ||\omega || = \sqrt{\omega_{1} ^{2} + ... + \omega_{n} ^{2}}
  $$

- 如图所示，根据支持向量的定义我们知道，支持向量到超平面的距离为 d，其他点到超平面的距离大于 d。
- ![image](https://cdn.jsdelivr.net/gh/poowicat/pic_store@main/blog/image.4d5xmd5lz5w.webp)

### 对偶问题

#### 拉格朗日乘子法

#### 强对偶性



#### SVM优化



### 软间隔

#### 解决问题

#### 优化目标及求解



### 核函数

- 在SVM算法中，训练模型的过程实际上是对每个数据点对于数据分类决定边界的重要性进行判断；

- 也就是说，在训练数据集中，只有一部分数据对于边界的确定是有帮助的；

- 而这些数据点就是正好位于决定边界上的，这些数据被称为“支持向量”；

- 下面用图像来直观理解一下：

- ```python
  # 导入numpy
  import numpy as np
  # 导入画图工具
  import matplotlib.pyplot as plt
  # 导入支持向量机SVM
  from sklearn import svm
  # 导入数据集生成工具
  from sklearn.datasets import make_blobs
  
  # 先创建50个数据点，分成两类
  x, y = make_blobs(n_samples=50, centers=2, random_state=6)
  
  # 创建一个线性内核的支持向量机模型
  clf = svm.SVC(kernel='linear', C=1000)
  clf.fit(x, y)
  
  # 把数据点画出来
  plt.scatter(x[:, 0], x[:, 1], c=y, s=30, cmap=plt.cm.Paired)
  
  # 建立图像坐标
  ax = plt.gca()
  xlim = ax.get_xlim()
  ylim = ax.get_ylim()
  
  
  # 生成两个等差数列
  xx = np.linspace(xlim[0], xlim[1], 30)
  yy = np.linspace(ylim[0], ylim[1], 30)
  yy, xx = np.meshgrid(yy, xx)
  xy = np.vstack([xx.ravel(), yy.ravel()]).T
  z = clf.decision_function(xy).reshape(xx.shape)
  
  # 把分类的决定边界画出来
  ax.contour(xx, yy, z, colors='k',
              levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])  # 外形
  ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[
             :, 1], s=100, linewidths=3, facecolors='none')
  plt.show()
  
  ```

 ![image](https://cdn.jsdelivr.net/gh/poowicat/pic_store@main/blog/image.49ynizlv4ty0.webp)

- 结果分析：从上图可看出，那些正好压在虚线上的数据点，就是我们刚刚提到的支持向量，而本例使用的这种方法称为”最大边界间隔超平面(MMSH) “

  - 指的是中间这条实线（在高维数据中是一个超平面），和所有支持向量之间的距离，都是最大的；

  - 如果把SVM换成RBF（高斯内核）会得到什么结果呢？

  - ```Python
    # 创建一个RBF内核的支持向量机模型
    clf_rbf = svm.SVC(kernel='rbf', C = 1000)
    clf_rbf.fit(x, y)
    # 把数据点画出来
    plt.scatter(x[:, 0], x[:, 1], c = y, s =30, cmap=plt.cm.Paired)
    
    # 建立图像坐标
    ax = plt.gca()
    xlim = ax.get_xlim()
    ylim = ax.get_ylim()
    
    # 生成两个等差数列
    xx = np.linspace(xlim[0], xlim[1], 30)
    yy = np.linspace(ylim[0], ylim[1], 30)
    yy, xx = np.meshgrid(yy, xx)
    xy = np.vstack([xx.ravel(), yy.ravel()]).T
    z = clf_rbf.decision_function(xy).reshape(xx.shape)
    
    # 把分类的决定边界画出来
    ax.contour(xx, yy, z, colors='k',
                levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])  # 外形
    ax.scatter(clf_rbf.support_vectors_[:, 0], clf_rbf.support_vectors_[
               :, 1], s=100, linewidths=1, facecolors='none')
    plt.show()
    
    ```

  ![image](https://cdn.jsdelivr.net/gh/poowicat/pic_store@main/blog/image.3ovaropajnc0.webp)

  - **结果分析：**

    - 从上图可以得出，分类器变得完全不一样了；只是因为当我们使用RBF内核的时候，数据点之前的距离使用如下公式进行计算的：
    ![image](https://cdn.jsdelivr.net/gh/poowicat/pic_store@main/blog/image.2oibgzt3nbi0.webp)
    - 公式中，x1和x2代表两个不同的数据点，而||x1-x2||代表两个点之间的欧几里得距离y（gamma)是用来控制RBF内核宽度的参数，也就是图中实线距离两条虚线的距离。

#### 线性不可分

#### SVM核函数与参数的选择

##### 不同核函数的SVM对比：



#### 核函数作用

#### 常见核函数

