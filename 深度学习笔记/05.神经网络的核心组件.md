### 训练神经网络主要围绕以下四个部分：

- **层**：用于合并成网络（或模型）
- **输入数据****和相应的目标**
- **损失函数**，定义了用于学习的反馈信号
- **优化器**，决定了学习如何进行

### 层：深度学习的基础组件

- 神经网络的基础数据结构是层，**层是一个数据处理模块**，它接受一个或多个张量作为输入，并输出一个或多个张量。有些层是无状态的，但更常见的层有一个状态：层的权值

- **不同的层适用于不同的张量格式和不同的数据类型的数据处理**

- 简单的矢量数据存储在二维张量的形状（Samples， features）中，通常由紧密的连接层（densely connected）处理。**也称为完全连接层或密集层**。

- 序列数据存储在形状为三维张量（samples， timesteps, features)中，通常由循环层（recurrent）处理，比如LSTM层。

- 图像数据存储在4D张量中，通常由二维卷积（Conv2D）处理。

- 代码实现：

  ```model = models.Sequential()```

  ```model.add(layers.Dense(32,input_shape=(784,)))```

  ```model.add(layers.Dense(32))```

  

### 模型：层构成的网络

深度学习模型是层构成的有向无环图，最常见的例子就是层的线性堆叠，将单一输入映射为单一输出。一些常见的网络拓扑结构如下：

- 双分支（tow-branch）网络
- 多头（multihead）网络
- inception模块

### 损失函数与优化器：配置学习过程的关键

- 一旦确定了网络架构，你还需要选择一下两个参数。
- **损失函数（目标函数）**—— 在训练过程中，需要将其最小化。它能够衡量当前认为是否已经成功完成。
- **优化器**—— 决定如何基于损失函数对网络进行更新。它执行的是孙吉梯度下降（SGD）的某个变体。
- 具有多个输出的神经网络可能具有多个损失函数**（每个输出对应一个损失函数）**，
- 因此，如果目标函数与成功完成当前任务不完全相关，那么网络最终得到的结果可能会不符合你的预期。
- 幸运的是，对于**分类、回归、序列预测**等常见问题，你可以遵循一些简单的指导原则来选择正确的损失函数。只有在面对真正全新的研究问题时，你才需要自主开发目标函数。
- **对于二分类问题**，可以使用 **二元交叉熵（binary crossentropy）**损失函数
- 对于 **多分类问题**，可以用 **分类交叉熵（categorical crossentropy）**损失函数；
- 对于 **回归问题**，可以用 **均分误差（mean-squared error）**损失函数；
- 对于 **序列学习问题**，可以用联结主义时序分类（CTC，connectionist temproal classification)损失函数，等等。
- 下一节我们将学习分类、回归、预测等常见问题的实际应用和相应代码实现。
- **附：神经网络四个部分之间的关系图如下：**
- ![image-20220128141149153](../%E5%9B%BE%E7%89%87/image-20220128141149153.png)





