# 评价分类器

- 理论上是主要性能测试（即得出综合的评价指标）

  

# 评估分类器性能的度量

正元组（正样本）：感兴趣的主要类的元组，P是正元组数。

负元组（负样本）：其他元组，N是负元组数。

混淆矩阵（confusion matrix）：

![img](https://i.loli.net/2021/09/23/WH5jiwtxe1QLlhI.png)

TP(True Positive):真正例/真阳性，是指被分类器正确分类的正元组

TN(True Negative):真负例/真阴性，是指被分类器正确分类的负元组

FP(False Positive):假正例/假阳性，是被错误地标记为正元组的负元组

FN(False Negative):假负例/假阴性，是被错误地标记为负元组的正元组

P’：被分类器标记为正的元组数(TP+FP)

N’：被分类器标记为负的元组数(TN+FN)

元组的总数=TP+TN+FP+FN=P+N=P'+N’

**准确率(accuracy)**:被分类器正确分类的元组所占的百分比，准确率又称为分类器的总体**识别率**，即它反映分类器对各类元组的正确识别情况，当类分布相对平衡时最有效。即

accuracy=(TP+TN)/(P+N)

**错误率(error rate,误分类率)**:error rate=(FP+FN)/(P+N)=1-accuracy

 

**灵敏性(sensitivity)、真正例率(**正确识别的正元组的百分比**):**sensitivity=TP/P

**特效性(specificity)、真负例率(**正确识别的负元组的百分比**)**:specificity=TN/N

准确率是灵敏性和特效性度量的函数：accuracy=(TP+TN)/(P+N)=TP/(P+N)*(P/P)+TN/(P+N)*(N/N)=sensitivity*P/(P+N)+specificity*N/(P+N)

 

**精度(precision)**:可以看作精确性的度量(标记为正类的元组实际为正类所占的百分比) precision=TP/(TP+FP)

**召回率(recall)**:完全性的度量(正元组标记为正的百分比),就是灵敏度 recall=TP/(TP+FN)=TP/P=sensitivity

![img](H:\Workplace\学习笔记\imgs\643534-20180803002017475-1621526136.png) 

除了基于准确率的度量外，还可以根据其他方面比较分类器：

**速度**：涉及产生和使用分类器的计算开销

**鲁棒性**：这是假定数据有噪声或有缺失值时分类器做出正确预测的能力。通常，鲁棒性用噪声和缺失值渐增的一系列合成数据集评估。

**可伸缩性**：这涉及给定大量数据，有效地构造分类器的能力。通常，可伸缩性用规模渐增的一系列数据集评估。

**可解释性**：这涉及分类器或预测器提供的理解和洞察水平。可解释性是主观的，很难评估。

当数据类比较均衡地分布时，准确率效果最好，其他度量，如灵敏度(或召回率)、特效性、精度、F和Fβ更适合不平衡问题。

 

## P-R曲线

查准率-查全率曲线，以查准率为纵轴，查全率为横轴作图。

 ![img](H:\Workplace\学习笔记\imgs\643534-20180808001041211-1478989383.png)

若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则后者性能优于前者，上图中学习器A的性能优于学习器C；如果两个学习器的P-R曲线发生了交叉，则需要比较P-R曲线下面积的大小，但这个面积不容易估算，通常综合考虑查准率、查全率的性能度量“平衡点(Break-Event Point,BEP)”,它是“查准率=查全率”时的取值。但BEP还是过于简化，更常用的是前面提到的F1度量。

 

## ROC与AUC

“最可能”是正例的样本排在最前面，“最不可能”是正例的排在最后面，按此排序。分类的过程就相当于在排序中以某个“截断点(cut point)”将样本分为两部分，前一部分判断正例，后一部分为反例。不同任务中根据需求划分截断点；重视查准率(精度)，靠前位置截断；重视查全率(召回率)，靠后位置截断。

ROC(Receiver Operating Characteristic,受试者工作特征)曲线是一种比较两个分类模型有用的可视化工具。ROC曲线显示了给定模型的真正例率(TPR)和假正例率(FPR)之间的权衡，纵轴是“真正例率(TPR)”,横轴是“假正例率(FPR)”。

![img](H:\Workplace\学习笔记\imgs\643534-20180807234519961-2095103312.png)

![img](H:\Workplace\学习笔记\imgs\643534-20180807234549340-1058858160.png)

图(a)中，给出了两条线，ROC曲线给出的是当阈值变化时假正例率和真正例率的变化情况。左下角的点所对应的是将所有样例判为反例的情况，而右上角的点对应的则是将所有样例判为正例的情况。虚线给出的是随机猜测的结果曲线。

现实任务中通常利用有限个测试样例来绘制ROC图，此时仅能获得有限个(真正例率，假正例率)坐标对，无法产生图(a)中光滑的ROC曲线，只能绘制如图(b)所示的近似ROC曲线。

 绘图过程：给定m+个正例和m-个反例，根据学习器预测结果对样例进行排序，然后把分类阈值设为最大，即把所有样例均预测为反例，此时真正例率和假正例率均为0，在坐标(0,0)处标记一个点。然后，将分类阈值依次设为每个样例的预测值，即依次将每个样例划分为正例。设前一个标记点坐标为(x,y),当前若为真正例，则对应标记点的坐标为(x,y+1/m+);当前若为假正例，则对应标记点的坐标为(x+1/m-,y),然后用线段连接相邻点即可。

若一个学习器的ROC曲线被另一个学习器的曲线完全“包住”，则可断言后者性能优于前者；如果曲线交叉，可以根据ROC曲线下面积大小进行比较，也即AUC(Area Under ROC Curve)值.

 AUC可通过对ROC曲线下各部分的面积求和而得。假定ROC曲线由坐标为{(x1,y1),(x2,y2),...,(xm,ym)}的点按序连接而形成(x1=0,xm=1),则AUC可估算为

![img](H:\Workplace\学习笔记\imgs\643534-20180807234804072-1861197240.png)

AUC给出的是分类器的平均性能值，它并不能代替对整条曲线的观察。一个完美的分类器的AUC为1.0，而随机猜测的AUC值为0.5

AUC考虑的是样本预测的排序质量，因此它与排序误差有紧密联系。给定m+个正例，m-个反例，令D+和D-分别表示正、反例集合，则排序”损失”定义为

 ![img](H:\Workplace\学习笔记\imgs\643534-20180807234903189-583592731.png)

Lrank对应ROC曲线之上的面积：若一个正例在ROC曲线上标记为(x,y)，则x恰是排序在期前的所有反例所占比例，即假正例，因此：

![img](H:\Workplace\学习笔记\imgs\643534-20180807234927345-1155860067.png)

AUC值是一个概率值，当你随机挑选一个正样本以及负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值，AUC值越大，当前分类算法越有可能将正样本排在负样本前面，从而能够更好地分类。

 

## 代价敏感错误率和代价曲线

现实任务中不同类型的错误所造成的后果很可能不同，为了权衡不同类型错误所造成的不同损失，可为错误赋予“非均等代价”。

以二分类为例，可根据领域知识设定“代价矩阵”，如下表所示，其中costij表示将第i类样本预测为第j类样本的代价。一般来说，costii=0;若将第0类判别为第1类所造成的损失更大，则cost01>cost10;损失程度越大,cost01与cost10值的差别越大。

![img](H:\Workplace\学习笔记\imgs\643534-20180808180252136-1134635948.png)

在非均等代价下，不再最小化错误次数，而是最小化“总体代价”，则“代价敏感”错误率相应的为：

 ![img](H:\Workplace\学习笔记\imgs\643534-20180808180348849-1507399276.png)

在非均等代价下，ROC曲线不能直接反映出学习器的期望总体代价，而“代价曲线(cost curve)”可以。代价曲线图的横轴是取值为[0,1]的正例概率代价

![img](H:\Workplace\学习笔记\imgs\643534-20180808180604622-1120419732.png)

其中p是样例为正例的概率；纵轴是取值为[0,1]的归一化代价

![img](H:\Workplace\学习笔记\imgs\643534-20180808180646163-301942706.png)

其中FPR是假正例率，FNR=1-TPR是假反例率。

代价曲线的绘制：ROC曲线上每个点对应了代价曲线上的一条线段，设ROC曲线上点的坐标为(TPR,FPR),则可相应计算出FNR,然后在代价平面上绘制一条从(0,FPR)到(1,FNR)的线段，线段下的面积即表示了该条件下的期望总体代价；如此将ROC曲线上的每个点转化为代价平面上的一条线段，然后取所有线段的下界，围成的面积即为所有条件下学习器的期望总体代价。

 ![img](H:\Workplace\学习笔记\imgs\643534-20180808180714342-844128471.png)
