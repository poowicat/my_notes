## **一、概念**

- **图像分类**，核心是从给定的分类集合中给图像分配一个标签的任务。
- 实际上，这意味着我们的任务是分析一个输入图像并返回一个将图像分类的标签。标签总是来自预定义的可能类别集。
- 评价指标是针对模型性能优劣的一个定量指标。
- 一种评价指标只能反映模型一部分性能，如果选择的评价指标不合理，那么可能会得出错误的结论，故而应该**针对具体的数据、模型选取不同**的的评价指标。




## **二、混淆矩阵（Confuse Matrix）**

针对一个二分类问题，即将实例分成正类（positive）或负类（negative），在实际分类中会出现以下四种情况：
（1）若一个实例是正类，并且被预测为正类，即为真正类TP(True Positive )
（2）若一个实例是正类，但是被预测为负类，即为假负类FN(False Negative )
（3）若一个实例是负类，但是被预测为正类，即为假正类FP(False Positive )
（4）若一个实例是负类，并且被预测为负类，即为真负类TN(True Negative )

混淆矩阵的每一行是样本的预测分类，每一列是样本的真实分类（反过来也可以）。



![img](H:\Workplace\学习笔记\imgs\v2-9c4d2f9faa4a240edca3c2d5a68f40e3_720w.jpg)



## 三、准确率（Accuracy）、精确率（Precision）、召回率（Recall）、F1 Score

### 1.准确率(Accuracy)

预测正确的样本数量占总量的百分比，具体的公式如下：

![](H:\Workplace\学习笔记\imgs\accuracy.svg)

准确率有一个**缺点**，就是数据的样本不均衡，这个指标是不能评价模型的性能优劣的。

假如一个测试集有正样本99个，负样本1个。模型把所有的样本都预测为正样本，那么模型的Accuracy为99%，看评价指标，模型的效果很好，但实际上模型没有任何预测能力。

### 2.精准率(Precision)

又称为**查准率**，是针对预测结果而言的一个评价指标。**在模型预测为正样本的结果中，真正是正样本所占的百分比**，具体公式如下：

![](H:\Workplace\学习笔记\imgs\P.svg)

精准率的含义就是在预测为正样本的结果中，有多少是准确的。这个指标比较谨慎，分类阈值较高。

### 3.召回率(Recall)

又称为**查全率**，是针对原始样本而言的一个评价指标。**在实际为正样本中，被预测为正样本所占的百分比。**具体公式如下：



尽量检测数据，不遗漏数据，所谓的宁肯错杀一千，不肯放过一个，分类阈值较低。

### 4.F1 Score

针对精准率和召回率都有其自己的缺点；如果阈值较高，那么精准率会高，但是会漏掉很多数据；如果阈值较低，召回率高，但是预测的会很不准确。

**例子一**

假设总共有10个好苹果，10个坏苹果。针对这20个数据，模型只预测了1个好苹果，对应结果如下表



![img](H:\Workplace\学习笔记\imgs\v2-8ee53d25586993bca5dcdbe47c68e6da_720w.jpg)

![[公式]](H:\Workplace\学习笔记\imgs\frac{1}{1%2B9}%3D0.1)

虽然精确率很高，但是这个模型的性能并不好。

**例子二**

同样总共有10个好苹果，10个坏苹果。针对这20个数据，模型把所有的苹果都预测为好苹果，对应结果如下表



![img](H:\Workplace\学习笔记\imgs\v2-3b2115c19cd14291aef7ede0a4ae4567_720w.jpg)

![](H:\Workplace\学习笔记\imgs\不平衡比较1.svg)

虽然召回率很高，但是这个模型的性能并不好。

从上述例子中，可以看到精确率和召回率是此消彼长的，如果要兼顾二者，就需要F1 Score。

![](H:\Workplace\学习笔记\imgs\不平衡比较2.svg)

F1 Score是一种**调和平均数。**

## 四、P-R曲线

P-R曲线是描述精确率和召回率变化的曲线。对于所有的正样本，

**绘制P-R曲线？**

设置不同的阈值，模型预测所有的正样本，计算对应的精准率和召回率。



![img](H:\Workplace\学习笔记\imgs\v2-a8d701e7b7070052a1dd830bae024e0d_720w.jpg)



模型与坐标轴围成的面积越大，则模型的性能越好。但一般来说，曲线下的面积是很难进行估算的，所以衍生出了“**平衡点**”（Break-Event Point，简称**BEP**），即当P=R时的取值，平衡点的取值越高，性能更优。

## 五、ROC曲线和AUC

### 1.为什么会有ROC？

**例子三**

有好苹果9个，坏苹果1个，模型把所有的苹果均预测为好苹果。



![img](H:\Workplace\学习笔记\imgs\v2-4506faee2c88141917c69b4439999922_720w.jpg)



![](H:\Workplace\学习笔记\imgs\例三.svg)

我们能够得出，尽管 Precision、Recall、F1都很高，但是模型效果却不好。所以针对样本不均衡，以上指标很难区分模型的性能，就需要用到ROC和AUC。

### 2.基本概念

对应的各个缩写含义：



![img](H:\Workplace\学习笔记\imgs\v2-9c4d2f9faa4a240edca3c2d5a68f40e3_720w.jpg)



在介绍ROC和AUC之前，我们需要明确以下三个概念：

**真正类率（true positive rate, TPR）**，也称为**灵敏度(sensitivity)**，等同于召回率。刻画的是被分类器正确分类的正实例占所有正实例的比例。

![](H:\Workplace\学习笔记\imgs\TPR.svg)

**真负类率（true negative rate, TNR）**，也称为**特异度(specificity)**，刻画的是被分类器正确分类的负实例占所有负实例的比例。

![](H:\Workplace\学习笔记\imgs\TNR.svg)

**负正类率（false positive rate, FPR）**，也称为1-specificity，计算的是被分类器错认为正类的负实例占所有负实例的比例。

![](H:\Workplace\学习笔记\imgs\FPR.svg)

### 3.ROC曲线

**ROC（Receiver Operating Characteristic）曲线，又称接受者操作特征曲线。**曲线对应的纵坐标是TPR，横坐标是FPR。
​

![img](H:\Workplace\学习笔记\imgs\v2-fad890b55fe2813a9e4a17e555da870d_720w.jpg)



绘制方法：

设置不同的阈值，会得到不同的TPR和FPR，而随着阈值的逐渐减小，越来越多的实例被划分为正类，但是这些正类中同样也掺杂着负类，即TPR和FPR会同时增大。阈值最大时，对应坐标点为（0,0），阈值最小时，对应坐标点（1,1）。

**理想目标： TPR=1, FPR=0，即图中(0,1)点。故ROC曲线越靠拢(0,1)点，即，越偏离45度对角线越好。对应的就是TPR越大越好，FPR越小越好。**

### 4.AUC

AUC(Area Under Curve)是处于ROC曲线下方的那部分面积的大小。AUC越大，代表模型的性能越好。

对于例子三的样本不均衡，对应的TPR=1，而FPR=1，能够判断模型性能不好。

总结

当正负样本差距不大的情况下，ROC和PR的趋势是差不多的，但是当负样本很多的时候，两者就截然不同了，ROC效果依然看似很好，但是PR上反映效果一般。ROC就不会出现例子一、二、三的情况。
