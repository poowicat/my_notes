---
title: 模型评估
date: 2022-06-14 10:31:23
permalink: /pages/dec16a/
categories:
  - 更多
  - 面试
tags:
  - 
author: 
  name: poowicat
  link: https://github.com/poowicat
---

**“没有测量，就没有科学。”**  —————— **科学家门捷列夫**

#### 01 评估指标的局限性

大部分指标只能片面的反映模型的一部分性能。如果不能合理的运行评估指标，不仅不能发现模型本身的问题，而且还会得出错误的结论。



##### 知识点：

准确率（Accuracy）、精确率（Precision）、召回率（Rcall）、均方根误差（ROOT Mean Square Error , RMSE）



##### Q1：准确率的局限性

###### 分析与解答：

- 准确率是最直观的评价指标
- 缺陷：当负样本为99%时，分类器把所有样本都预测为负样本，也可以获得99%的准确率
- 结论：当不同类别样本比例非常不均衡时，占比大的类别往往是影响准确率最主要的因素
- 解决： 引入 **平均准确率**



##### Q2：精确率和召回率的权衡

例子：推荐模型，搜索排序模型返回Top5的精确率非常高，但实际使用过程中，用户还是经常找不到想要的视频。问题出现在哪？

###### 分析与解答：

- P R值是个矛盾又统一的指标，为了提高Precision 值，分类器要尽量“更有把握”才能把样本预测为正样本 
- 但此时，往往因为过于保守，而漏掉很多没有把握的正样本，导致Recall降低
- 回到问题上来，显然问题出现在召回率Recall上；
- P-R曲线，一个点代表着，在某一阈值下，模型将大于该阈值的结果，判定为正样本，反之。结果判定为负样本。
- P-R曲线充分说明，只用某个点对应的精确率和召回率是不能全面地衡量模型的性能。
- 只有通过P-R曲线的整体表现，才能够对模型进行更为全面的评估
- 此外，用F1 score和ROC曲线能综合的反映一个排序模型的性能；



##### Q3: 平方根误差的“意外”

###### 例子:

Hulu公司预测某部美剧流量趋势，以来对于广告投放、用户增长都非常重要。希望构架一个回归模型来预测某部美剧的流量趋势，但无论采用哪种回归模型，得到的RMSE指标非常高。然而事实是，模型在95%的时间区间内的预测误差都小于1%。导致RMSE指标居高不下的最可能原因是什么？



###### 分析与解答

- RMSE经常用来衡量 **回归模型的好坏**

- 上述问题中，RMSE确失效了

- 先看一下RMSE公式：

  ![image](C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.i82y7ujxc3s.webp)

- 其中，yi是第i个样本点的真实值， 是第i个样本点的预测值，n是样本点的个数。

- 原因：个别偏离程度非常大的离群点，会让RMSE存在很大误差

- 解决方案：

  1. 数据预处理阶段：噪声过滤

  2. 提高模型的预测能力，将离群点产生的机制建模进去

  3. 存在比RMSE鲁棒性更强的指标，比如 **平均百分比误差**

     ![image](C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.x50800p74r4.webp)

  - **MAPE**相当于把每个点的误差进行了归一化，**降低**了个别离群点带来 的绝对误差的影响。

- 总结：以上例子，说明了选择合适的评估指标的重要性



#### 07  过拟合和欠拟合

##### 过拟合

- 指模型对训练数据拟合呈过当情况，反映到评估指标上，就是模型在**训练集**上表现**良好**，但是**测试集和新数据集上，**表现较**差**

##### 降低过拟合风险方法

1. 从数据入手，获得更多训练数据集。因为更多样本能让模型学习到更多更有效的特征，减小噪声的影响；
2. 降低模型复杂度；例如减少网络中的层数、神经元个数等；在决策树中降低树的深度、进行剪枝等。
3. 正则化方法。给模型的参数加上一定的正则约束。
4. 集成学习方法。把多个模型集成在一起，来降低模型的过拟合风险，如Bagging方法。

##### 欠拟合

- 欠拟合就是模型在训练和预训练时表现都不好

##### 降低欠拟合方法

1. 添加新特征
2. 增加模型复杂度
3. 减小正则化系数







